{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsIDAKfo6ha6"
      },
      "source": [
        "# MNIST 실습 (Pytorch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02aQ79aA6ha7"
      },
      "source": [
        "# 1. 환경 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jZtnC00b6ha7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xOSFRuD6ha7"
      },
      "source": [
        "*먼저, GPU 사용 여부를 결정합니다.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etOHzERc6ha7",
        "outputId": "b6bf15a9-f9a2-43b6-c94a-d44581e8c5e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\" )\n",
        "    use_cuda = True\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    use_cuda = False\n",
        "\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5KINtXQCQue"
      },
      "source": [
        "# 2. 데이터 준비"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXZzjUD-6ha7"
      },
      "source": [
        "- 토치에서 random seed를 고정하기 위해 manual_seed()를 사용한다.\n",
        "- random seed를 고정한다는 말은 동일한 셋트의 난수를 생성할 수 있게 하는 것이다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUjn6pxQ_bOQ",
        "outputId": "ebe6708a-2dc9-49a9-ef0f-4ea843f2a5f6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x78e80c5d7d70>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "seed = 1\n",
        "torch.manual_seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNhQI0CRp_rJ"
      },
      "source": [
        "데이터를 불러오기 전에 데이터 전처리 과정을 미리 정의하기\n",
        "\n",
        "---\n",
        "\n",
        "torchvision.transforms 모듈은\n",
        "1. pre-processing\n",
        "2. data augmentation\n",
        "아래 링크 참고하기\n",
        "\n",
        "https://wikidocs.net/194919\n",
        "\n",
        "---\n",
        "\n",
        "ToTensor() 사용 이유\n",
        "\n",
        "1. 배열구조 변환\n",
        "이미지 또는 넘파이 배열은 HWC순이다.\n",
        "ToTensor()를 사용하면 토치의 배열 구조인 CHW로 변환해준다.\n",
        "\n",
        "2. 값의 크기를 조정(scaling)\n",
        "0-255 → 0-1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "D_a8NbUrpkNQ"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor() # 텐서로 변환\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nO31Orm76ha7"
      },
      "source": [
        "Train, validation, test data를 설정합시다.\n",
        "\n",
        "---\n",
        "\n",
        "Dataset 은 샘플과 정답(label)을 저장하고\n",
        "dataset 클래스는 __len__()과 __getitem__()이 꼭 있어야 함!\n",
        "\n",
        "DataLoader 는 Dataset 을 샘플에 쉽게 접근할 수 있도록 순회 가능한 객체(iterable)로 감쌉니다.\n",
        "- 이때 중요한 것은 batch 크기 데이터를 불러오는 걸 해준다.\n",
        "\n",
        "- shuffle = true : each epoch 마다 데이터 학습되는 순서가 변경된다.\n",
        "\n",
        "아래 링크 참고하기\n",
        "https://wikidocs.net/156998\n",
        "\n",
        "---\n",
        "torch.utils.data.random_split()함수\n",
        "- 데이터를 random 하게 split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "683pcSv06ha7"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "test_batch_size = 1024\n",
        "\n",
        "train_ratio = 0.8\n",
        "validation_ratio = 0.2\n",
        "\n",
        "mnist_train = datasets.MNIST('../data', train=True, download=True, transform=transform)\n",
        "mnist_test = datasets.MNIST('../data', train=False, download=True, transform=transform)\n",
        "len_mnist_train = len(mnist_train)\n",
        "train_size = int(len_mnist_train * train_ratio)\n",
        "validation_size = int(len_mnist_train * validation_ratio)\n",
        "\n",
        "train_dataset, validation_dataset = torch.utils.data.random_split(mnist_train, [train_size, validation_size])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size, shuffle=True)\n",
        "validation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size = batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(mnist_test, batch_size=test_batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuDgBNhl6ha8"
      },
      "source": [
        "*다운받은 data를 확인해보겠습니다.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udrrzS2K6ha8",
        "outputId": "7c04254c-b18b-433d-aaaa-b2e550dbc936"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32, 1, 28, 28])\n",
            "tensor([3, 4, 7, 2, 9, 3, 9, 5, 8, 9, 7, 7, 7, 1, 9, 5, 7, 0, 3, 3, 4, 3, 7, 3,\n",
            "        4, 8, 7, 9, 4, 3, 5, 3])\n",
            "배치 크기: 32\n"
          ]
        }
      ],
      "source": [
        "# 해당 셀을 계속해서 실행하면 next()함수로 인해 다음 데이터가 반환된다.\n",
        "# 그래서 출력 결과가 매번 다를 것이다.\n",
        "it_train = iter(train_loader)\n",
        "img, label = next(it_train) # train loader에서 하나씩 꺼내려면 iter를 사용하면 된다.\n",
        "#train x, train y\n",
        "\n",
        "print(img.shape) # torch.Size는 순서대로 ([batch_size, color, height, width])를 의미합니다.\n",
        "print(label)\n",
        "print(f\"배치 크기: {len(label)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJLPSuCf6ha8"
      },
      "source": [
        "\n",
        "\n",
        "*batch_size와 color 차원을 제거하고 이미지를 랜더링 해봅시다.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "-muaftjV6ha8",
        "outputId": "0b4c69bf-1cb5-473d-d5fd-16da8f999d0c"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(3)\n"
          ]
        }
      ],
      "source": [
        "index = 0\n",
        "img_show = img[index, 0, :, :] # 암기하기     [ batchsize, channel, height, width ]\n",
        "plt.imshow(img_show, 'gray') # plt.imshow() 함수는 좌표평면 위에 이미지를 출력\n",
        "plt.show() # 이건 imshow() 다음에 꼭 사용하기\n",
        "print(label[index])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlUp8Q8_Coju"
      },
      "source": [
        "# 3. 모델 정의\n",
        "\n",
        "모델 1은\n",
        "- 레이어1: 16개의 노드\n",
        "- 레이어2: 10개의 노드"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPspXJgA49Yj"
      },
      "source": [
        "이때 torch.nn.Module을 상속받아야 한다. (상속: 어떤 클래스를 만들 때 다른 클래스의 기능을 가져오는 것)\n",
        "\n",
        "이때 __init()__과 forward()를 override해야한다. (override: 부모 클래스인 torch.nn.Module에서 정의한 메소드를 자식 클래스에서 변경하는 것)\n",
        "- __init()__ : layer를 정의하는 곳\n",
        "- forward() : 모델에서 실행되는 계산을 정의. backward()는 토치에서 알아서 해준다!\n",
        "\n",
        "---\n",
        "\n",
        "forward() 함수\n",
        "- 보면, view() 함수를 사용한다. view는 reshape하는 함수이다. 링크를 참고해라! (https://jimmy-ai.tistory.com/151)\n",
        "- F.log_softmax()함수는 log(softmax)랑 같은 개념. softmax 사용 시 vanishing gradient 문제 때문에, 이걸 사용하는 경우가 많음."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "x_TzBWET6ha9"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork(torch.nn.Module): # 토치에서는 모델을 정의할 때 class로 만들어야한다.\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "\n",
        "        # Layer 정의\n",
        "        self.fc1 = nn.Linear(784, 16)\n",
        "        self.fc2 = nn.Linear(16, 10)\n",
        "\n",
        "  # Layer 쌓기\n",
        "    def forward(self, x):\n",
        "        x = x.float() # x는 입력받는 이미지를 의미함\n",
        "        h1 = F.relu(self.fc1(x.view(-1, 784))) # import torch.nn.functional as F\n",
        "        h2 = self.fc2(h1)\n",
        "        return F.log_softmax(h2, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "Hz_4JfVm6ha-"
      },
      "outputs": [],
      "source": [
        "model = NeuralNetwork().to(device) # to(device)로 모델 gpu에 보내기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlE2x-sxoGml"
      },
      "source": [
        "# 4. 모델 학습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGfWQrgnpEE-"
      },
      "source": [
        "아래는 enumerate의 실행 결과\n",
        "\n",
        "```\n",
        "list1 = [1, 2, 3, 4, 5, 6, 10]\n",
        "for idx, data in enumerate(list1):\n",
        "    print(idx, data)\n",
        "\n",
        "0 1\n",
        "1 2\n",
        "2 3\n",
        "3 4\n",
        "4 5\n",
        "5 6\n",
        "6 10\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NVwg9Zv6ha-"
      },
      "source": [
        "*네트워크를 학습시키기 위해서 train 함수를 정의합니다.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "TDfXDYWn6ha-"
      },
      "outputs": [],
      "source": [
        "def train(log_interval, model, device, train_loader, optimizer, epoch):\n",
        "    flag = True\n",
        "    for batch_idx, (data, target) in enumerate(train_loader): # data를 하나씩 주는 게 아니라 batch 크기만큼 준다. 그래서 batch_idx를 사용하는 것이다.\n",
        "        data, target = data.to(device), target.to(device) # 데이터를 target device에 올려야 한다.\n",
        "        optimizer.zero_grad() # optimzer를 초기화\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target) # nll_loss(log_softmax) = cross entropy loss. 이미 forward 연산에서 log_softmax를 사용했으니깐, 요기서는 그냥 nll_loss만 사용해도 된다.\n",
        "        loss.backward() # backprop을 통한 gradient 계산\n",
        "        optimizer.step() # 실제 parameter의 값이 update되는 코드\n",
        "\n",
        "        if flag:\n",
        "          flag = False\n",
        "          print(target.shape, output.shape)\n",
        "\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch+1, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOyL39QhxAT4"
      },
      "source": [
        "*네트워크를 검증하기 위해서 validation 함수를 정의합니다.*\n",
        "\n",
        "---\n",
        "\n",
        "nll_loss()함수의 자세한 설명\n",
        "- nll_loss() 함수를 통해 계산된 loss는 item() 함수로 가져올 수 있다!\n",
        "- 이때 reduction='sum'을 사용하면, mini-batch안에 있는 모든 sample에 대한 loss를 sum하게 된다.\n",
        "- 만약, reduction='mean' (default setting)을 하면, batch안에 있는 모든 sample의 loss에 대한 평균을 구한다. 이건 training 때 사용되는 방법이다\n",
        "---\n",
        "argmax() 함수 실행 예시\n",
        "```\n",
        "#코드\n",
        "it = iter(train_loader)\n",
        "data, target = next(it)\n",
        "data, target = data.to(device), target.to(device)\n",
        "output = model(data)\n",
        "print(output[0])\n",
        "pred = output.argmax(dim=1, keepdim=True) # dim = 0은 열 기준, dim = 1은 행 기준으로 max 값의 idx를 반환\n",
        "print(pred[[0]])\n",
        "\n",
        "#결과\n",
        "tensor([-2.4081, -2.3636, -2.2304, -2.1932, -2.4621, -2.4544, -2.3904, -2.2540,\n",
        "        -2.2461, -2.0929], device='cuda:0', grad_fn=<SelectBackward0>)\n",
        "tensor([[9]], device='cuda:0')\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "I3qsed7ww1e2"
      },
      "outputs": [],
      "source": [
        "def validation(model, device, validation_loader):\n",
        "    validation_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad(): #gradient calculation을 하지 않아서 computation 절약 가능\n",
        "        for data, target in validation_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            validation_loss += F.nll_loss(output, target, reduction='sum').item()\n",
        "            pred = output.argmax(dim=1, keepdim=True) # keepdim=True는 차원 유지하고 싶을 때 사용하는 코드인데, 굳이 알 필요 없다\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "            # eq()함수는 각 텐서의 element-wise하게 비교하여 같다면 true 반환, 틀리면 false 반환\n",
        "            # target.view_as(pred)는 pred의 shape과 target이 같도록 reshape하는 방법\n",
        "            # 그 다음 sum, item은 일단 몰라도 된다. skip하자\n",
        "\n",
        "\n",
        "    validation_loss /= len(validation_loader.dataset) # dataset의 길이만큼 나누니깐 validation dataset 전체의 개수로 나누는 것이다. 즉, validation dataset loss의 평균을 구하는 식을 의미한다.\n",
        "\n",
        "    print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format\n",
        "          (validation_loss, correct, len(validation_loader.dataset),\n",
        "        100. * correct / len(validation_loader.dataset)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKX45eTT6ha-"
      },
      "source": [
        "*네트워크의 학습 결과를 보기 위해서 test 함수를 정의합니다.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "nLLVVbh66ha-"
      },
      "outputs": [],
      "source": [
        "def test(model, device, test_loader):\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad(): #gradient calculation을 하지 않아서 computation 절약 가능\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format\n",
        "          (test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "g2oH_VqI6ha7"
      },
      "outputs": [],
      "source": [
        "epochs = 50\n",
        "lr = 0.01           # learning rate\n",
        "momentum = 0.5      # optimizer parameter\n",
        "log_interval = 200\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
        "# kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {} # num of workers랑 pin memory는 나중에 공부하기. 지금은 몰라도 된다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3z_sqcLg6ha-"
      },
      "source": [
        "*위에서 정의한 함수를 사용하여 네트워크 학습을 진행 해봅시다.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEwkYP9n6ha_",
        "outputId": "14cd9abc-dd33-45a2-c5e6-e61e762cc75e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32]) torch.Size([32, 10])\n",
            "Train Epoch: 1 [0/48000 (0%)]\tLoss: 2.279796\n",
            "Train Epoch: 1 [6400/48000 (13%)]\tLoss: 1.216280\n",
            "Train Epoch: 1 [12800/48000 (27%)]\tLoss: 0.741805\n",
            "Train Epoch: 1 [19200/48000 (40%)]\tLoss: 0.566434\n",
            "Train Epoch: 1 [25600/48000 (53%)]\tLoss: 0.740583\n",
            "Train Epoch: 1 [32000/48000 (67%)]\tLoss: 0.327765\n",
            "Train Epoch: 1 [38400/48000 (80%)]\tLoss: 0.826041\n",
            "Train Epoch: 1 [44800/48000 (93%)]\tLoss: 0.169102\n",
            "\n",
            "Validation set: Average loss: 0.3826, Accuracy: 10664/12000 (89%)\n",
            "\n",
            "torch.Size([32]) torch.Size([32, 10])\n",
            "Train Epoch: 2 [0/48000 (0%)]\tLoss: 0.245812\n",
            "Train Epoch: 2 [6400/48000 (13%)]\tLoss: 0.512036\n",
            "Train Epoch: 2 [12800/48000 (27%)]\tLoss: 0.361296\n",
            "Train Epoch: 2 [19200/48000 (40%)]\tLoss: 0.239665\n",
            "Train Epoch: 2 [25600/48000 (53%)]\tLoss: 0.205330\n",
            "Train Epoch: 2 [32000/48000 (67%)]\tLoss: 0.410364\n",
            "Train Epoch: 2 [38400/48000 (80%)]\tLoss: 0.246055\n",
            "Train Epoch: 2 [44800/48000 (93%)]\tLoss: 0.137219\n",
            "\n",
            "Validation set: Average loss: 0.3327, Accuracy: 10856/12000 (90%)\n",
            "\n",
            "torch.Size([32]) torch.Size([32, 10])\n",
            "Train Epoch: 3 [0/48000 (0%)]\tLoss: 0.239962\n",
            "Train Epoch: 3 [6400/48000 (13%)]\tLoss: 0.584900\n",
            "Train Epoch: 3 [12800/48000 (27%)]\tLoss: 0.231256\n",
            "Train Epoch: 3 [19200/48000 (40%)]\tLoss: 0.339476\n",
            "Train Epoch: 3 [25600/48000 (53%)]\tLoss: 0.396283\n",
            "Train Epoch: 3 [32000/48000 (67%)]\tLoss: 0.158808\n",
            "Train Epoch: 3 [38400/48000 (80%)]\tLoss: 0.100943\n",
            "Train Epoch: 3 [44800/48000 (93%)]\tLoss: 0.511130\n",
            "\n",
            "Validation set: Average loss: 0.3041, Accuracy: 10939/12000 (91%)\n",
            "\n",
            "torch.Size([32]) torch.Size([32, 10])\n",
            "Train Epoch: 4 [0/48000 (0%)]\tLoss: 0.280360\n",
            "Train Epoch: 4 [6400/48000 (13%)]\tLoss: 0.208797\n",
            "Train Epoch: 4 [12800/48000 (27%)]\tLoss: 0.060162\n",
            "Train Epoch: 4 [19200/48000 (40%)]\tLoss: 0.259683\n",
            "Train Epoch: 4 [25600/48000 (53%)]\tLoss: 0.268436\n",
            "Train Epoch: 4 [32000/48000 (67%)]\tLoss: 0.199535\n",
            "Train Epoch: 4 [38400/48000 (80%)]\tLoss: 0.425739\n",
            "Train Epoch: 4 [44800/48000 (93%)]\tLoss: 0.111526\n",
            "\n",
            "Validation set: Average loss: 0.2892, Accuracy: 10977/12000 (91%)\n",
            "\n",
            "torch.Size([32]) torch.Size([32, 10])\n",
            "Train Epoch: 5 [0/48000 (0%)]\tLoss: 0.208695\n",
            "Train Epoch: 5 [6400/48000 (13%)]\tLoss: 0.245185\n",
            "Train Epoch: 5 [12800/48000 (27%)]\tLoss: 0.181626\n",
            "Train Epoch: 5 [19200/48000 (40%)]\tLoss: 0.420235\n",
            "Train Epoch: 5 [25600/48000 (53%)]\tLoss: 0.227717\n",
            "Train Epoch: 5 [32000/48000 (67%)]\tLoss: 0.353995\n",
            "Train Epoch: 5 [38400/48000 (80%)]\tLoss: 0.328915\n",
            "Train Epoch: 5 [44800/48000 (93%)]\tLoss: 0.132069\n",
            "\n",
            "Validation set: Average loss: 0.2801, Accuracy: 11024/12000 (92%)\n",
            "\n",
            "torch.Size([32]) torch.Size([32, 10])\n",
            "Train Epoch: 6 [0/48000 (0%)]\tLoss: 0.141269\n",
            "Train Epoch: 6 [6400/48000 (13%)]\tLoss: 0.210291\n",
            "Train Epoch: 6 [12800/48000 (27%)]\tLoss: 0.306635\n",
            "Train Epoch: 6 [19200/48000 (40%)]\tLoss: 0.353991\n",
            "Train Epoch: 6 [25600/48000 (53%)]\tLoss: 0.087227\n",
            "Train Epoch: 6 [32000/48000 (67%)]\tLoss: 0.231108\n",
            "Train Epoch: 6 [38400/48000 (80%)]\tLoss: 0.135878\n",
            "Train Epoch: 6 [44800/48000 (93%)]\tLoss: 0.277734\n",
            "\n",
            "Validation set: Average loss: 0.2748, Accuracy: 11058/12000 (92%)\n",
            "\n",
            "torch.Size([32]) torch.Size([32, 10])\n",
            "Train Epoch: 7 [0/48000 (0%)]\tLoss: 0.040373\n",
            "Train Epoch: 7 [6400/48000 (13%)]\tLoss: 0.293843\n",
            "Train Epoch: 7 [12800/48000 (27%)]\tLoss: 0.628972\n",
            "Train Epoch: 7 [19200/48000 (40%)]\tLoss: 0.097472\n",
            "Train Epoch: 7 [25600/48000 (53%)]\tLoss: 0.192557\n",
            "Train Epoch: 7 [32000/48000 (67%)]\tLoss: 0.182458\n",
            "Train Epoch: 7 [38400/48000 (80%)]\tLoss: 0.174499\n",
            "Train Epoch: 7 [44800/48000 (93%)]\tLoss: 0.253041\n",
            "\n",
            "Validation set: Average loss: 0.2576, Accuracy: 11091/12000 (92%)\n",
            "\n",
            "torch.Size([32]) torch.Size([32, 10])\n",
            "Train Epoch: 8 [0/48000 (0%)]\tLoss: 0.396053\n",
            "Train Epoch: 8 [6400/48000 (13%)]\tLoss: 0.373726\n",
            "Train Epoch: 8 [12800/48000 (27%)]\tLoss: 0.285379\n",
            "Train Epoch: 8 [19200/48000 (40%)]\tLoss: 0.313342\n",
            "Train Epoch: 8 [25600/48000 (53%)]\tLoss: 0.355293\n",
            "Train Epoch: 8 [32000/48000 (67%)]\tLoss: 0.191179\n",
            "Train Epoch: 8 [38400/48000 (80%)]\tLoss: 0.416496\n",
            "Train Epoch: 8 [44800/48000 (93%)]\tLoss: 0.095610\n",
            "\n",
            "Validation set: Average loss: 0.2504, Accuracy: 11111/12000 (93%)\n",
            "\n",
            "torch.Size([32]) torch.Size([32, 10])\n",
            "Train Epoch: 9 [0/48000 (0%)]\tLoss: 0.049016\n",
            "Train Epoch: 9 [6400/48000 (13%)]\tLoss: 0.190019\n",
            "Train Epoch: 9 [12800/48000 (27%)]\tLoss: 0.127470\n",
            "Train Epoch: 9 [19200/48000 (40%)]\tLoss: 0.162045\n",
            "Train Epoch: 9 [25600/48000 (53%)]\tLoss: 0.167712\n",
            "Train Epoch: 9 [32000/48000 (67%)]\tLoss: 0.258116\n",
            "Train Epoch: 9 [38400/48000 (80%)]\tLoss: 0.187718\n",
            "Train Epoch: 9 [44800/48000 (93%)]\tLoss: 0.222826\n",
            "\n",
            "Validation set: Average loss: 0.2424, Accuracy: 11142/12000 (93%)\n",
            "\n",
            "torch.Size([32]) torch.Size([32, 10])\n",
            "Train Epoch: 10 [0/48000 (0%)]\tLoss: 0.351986\n",
            "Train Epoch: 10 [6400/48000 (13%)]\tLoss: 0.205883\n",
            "Train Epoch: 10 [12800/48000 (27%)]\tLoss: 0.269092\n",
            "Train Epoch: 10 [19200/48000 (40%)]\tLoss: 0.078186\n",
            "Train Epoch: 10 [25600/48000 (53%)]\tLoss: 0.338790\n",
            "Train Epoch: 10 [32000/48000 (67%)]\tLoss: 0.319164\n",
            "Train Epoch: 10 [38400/48000 (80%)]\tLoss: 0.123679\n",
            "Train Epoch: 10 [44800/48000 (93%)]\tLoss: 0.534571\n",
            "\n",
            "Validation set: Average loss: 0.2390, Accuracy: 11148/12000 (93%)\n",
            "\n",
            "torch.Size([32]) torch.Size([32, 10])\n",
            "Train Epoch: 11 [0/48000 (0%)]\tLoss: 0.072889\n",
            "Train Epoch: 11 [6400/48000 (13%)]\tLoss: 0.121799\n",
            "Train Epoch: 11 [12800/48000 (27%)]\tLoss: 0.341198\n",
            "Train Epoch: 11 [19200/48000 (40%)]\tLoss: 0.060640\n",
            "Train Epoch: 11 [25600/48000 (53%)]\tLoss: 0.122843\n",
            "Train Epoch: 11 [32000/48000 (67%)]\tLoss: 0.313681\n",
            "Train Epoch: 11 [38400/48000 (80%)]\tLoss: 0.354732\n",
            "Train Epoch: 11 [44800/48000 (93%)]\tLoss: 0.082369\n",
            "\n",
            "Validation set: Average loss: 0.2326, Accuracy: 11159/12000 (93%)\n",
            "\n",
            "torch.Size([32]) torch.Size([32, 10])\n",
            "Train Epoch: 12 [0/48000 (0%)]\tLoss: 0.258014\n",
            "Train Epoch: 12 [6400/48000 (13%)]\tLoss: 0.228003\n",
            "Train Epoch: 12 [12800/48000 (27%)]\tLoss: 0.403134\n",
            "Train Epoch: 12 [19200/48000 (40%)]\tLoss: 0.279866\n",
            "Train Epoch: 12 [25600/48000 (53%)]\tLoss: 0.208310\n",
            "Train Epoch: 12 [32000/48000 (67%)]\tLoss: 0.169621\n",
            "Train Epoch: 12 [38400/48000 (80%)]\tLoss: 0.147728\n",
            "Train Epoch: 12 [44800/48000 (93%)]\tLoss: 0.099583\n",
            "\n",
            "Validation set: Average loss: 0.2285, Accuracy: 11191/12000 (93%)\n",
            "\n",
            "torch.Size([32]) torch.Size([32, 10])\n",
            "Train Epoch: 13 [0/48000 (0%)]\tLoss: 0.144102\n",
            "Train Epoch: 13 [6400/48000 (13%)]\tLoss: 0.241310\n",
            "Train Epoch: 13 [12800/48000 (27%)]\tLoss: 0.279896\n",
            "Train Epoch: 13 [19200/48000 (40%)]\tLoss: 0.164439\n",
            "Train Epoch: 13 [25600/48000 (53%)]\tLoss: 0.077324\n",
            "Train Epoch: 13 [32000/48000 (67%)]\tLoss: 0.236050\n",
            "Train Epoch: 13 [38400/48000 (80%)]\tLoss: 0.289238\n",
            "Train Epoch: 13 [44800/48000 (93%)]\tLoss: 0.273976\n",
            "\n",
            "Validation set: Average loss: 0.2225, Accuracy: 11210/12000 (93%)\n",
            "\n",
            "torch.Size([32]) torch.Size([32, 10])\n",
            "Train Epoch: 14 [0/48000 (0%)]\tLoss: 0.071313\n",
            "Train Epoch: 14 [6400/48000 (13%)]\tLoss: 0.082649\n",
            "Train Epoch: 14 [12800/48000 (27%)]\tLoss: 0.224606\n",
            "Train Epoch: 14 [19200/48000 (40%)]\tLoss: 0.069125\n",
            "Train Epoch: 14 [25600/48000 (53%)]\tLoss: 0.104680\n",
            "Train Epoch: 14 [32000/48000 (67%)]\tLoss: 0.096017\n",
            "Train Epoch: 14 [38400/48000 (80%)]\tLoss: 0.096882\n",
            "Train Epoch: 14 [44800/48000 (93%)]\tLoss: 0.092197\n",
            "\n",
            "Validation set: Average loss: 0.2213, Accuracy: 11218/12000 (93%)\n",
            "\n",
            "torch.Size([32]) torch.Size([32, 10])\n",
            "Train Epoch: 15 [0/48000 (0%)]\tLoss: 0.110907\n",
            "Train Epoch: 15 [6400/48000 (13%)]\tLoss: 0.202490\n",
            "Train Epoch: 15 [12800/48000 (27%)]\tLoss: 0.139456\n",
            "Train Epoch: 15 [19200/48000 (40%)]\tLoss: 0.223567\n",
            "Train Epoch: 15 [25600/48000 (53%)]\tLoss: 0.305823\n",
            "Train Epoch: 15 [32000/48000 (67%)]\tLoss: 0.222133\n",
            "Train Epoch: 15 [38400/48000 (80%)]\tLoss: 0.099428\n",
            "Train Epoch: 15 [44800/48000 (93%)]\tLoss: 0.247052\n",
            "\n",
            "Validation set: Average loss: 0.2169, Accuracy: 11215/12000 (93%)\n",
            "\n",
            "torch.Size([32]) torch.Size([32, 10])\n",
            "Train Epoch: 16 [0/48000 (0%)]\tLoss: 0.034201\n",
            "Train Epoch: 16 [6400/48000 (13%)]\tLoss: 0.389731\n",
            "Train Epoch: 16 [12800/48000 (27%)]\tLoss: 0.158700\n",
            "Train Epoch: 16 [19200/48000 (40%)]\tLoss: 0.362977\n",
            "Train Epoch: 16 [25600/48000 (53%)]\tLoss: 0.398257\n",
            "Train Epoch: 16 [32000/48000 (67%)]\tLoss: 0.099470\n",
            "Train Epoch: 16 [38400/48000 (80%)]\tLoss: 0.352474\n",
            "Train Epoch: 16 [44800/48000 (93%)]\tLoss: 0.326973\n",
            "\n",
            "Validation set: Average loss: 0.2078, Accuracy: 11253/12000 (94%)\n",
            "\n",
            "torch.Size([32]) torch.Size([32, 10])\n",
            "Train Epoch: 17 [0/48000 (0%)]\tLoss: 0.300816\n",
            "Train Epoch: 17 [6400/48000 (13%)]\tLoss: 0.177264\n",
            "Train Epoch: 17 [12800/48000 (27%)]\tLoss: 0.127155\n",
            "Train Epoch: 17 [19200/48000 (40%)]\tLoss: 0.247923\n",
            "Train Epoch: 17 [25600/48000 (53%)]\tLoss: 0.072513\n",
            "Train Epoch: 17 [32000/48000 (67%)]\tLoss: 0.361187\n",
            "Train Epoch: 17 [38400/48000 (80%)]\tLoss: 0.176885\n",
            "Train Epoch: 17 [44800/48000 (93%)]\tLoss: 0.103044\n",
            "\n",
            "Validation set: Average loss: 0.2044, Accuracy: 11265/12000 (94%)\n",
            "\n",
            "torch.Size([32]) torch.Size([32, 10])\n",
            "Train Epoch: 18 [0/48000 (0%)]\tLoss: 0.363661\n",
            "Train Epoch: 18 [6400/48000 (13%)]\tLoss: 0.105015\n",
            "Train Epoch: 18 [12800/48000 (27%)]\tLoss: 0.126446\n",
            "Train Epoch: 18 [19200/48000 (40%)]\tLoss: 0.144522\n",
            "Train Epoch: 18 [25600/48000 (53%)]\tLoss: 0.079200\n",
            "Train Epoch: 18 [32000/48000 (67%)]\tLoss: 0.100367\n",
            "Train Epoch: 18 [38400/48000 (80%)]\tLoss: 0.182999\n",
            "Train Epoch: 18 [44800/48000 (93%)]\tLoss: 0.215128\n",
            "\n",
            "Validation set: Average loss: 0.2035, Accuracy: 11282/12000 (94%)\n",
            "\n",
            "torch.Size([32]) torch.Size([32, 10])\n",
            "Train Epoch: 19 [0/48000 (0%)]\tLoss: 0.259226\n",
            "Train Epoch: 19 [6400/48000 (13%)]\tLoss: 0.032054\n",
            "Train Epoch: 19 [12800/48000 (27%)]\tLoss: 0.075714\n",
            "Train Epoch: 19 [19200/48000 (40%)]\tLoss: 0.128391\n",
            "Train Epoch: 19 [25600/48000 (53%)]\tLoss: 0.161298\n",
            "Train Epoch: 19 [32000/48000 (67%)]\tLoss: 0.510311\n",
            "Train Epoch: 19 [38400/48000 (80%)]\tLoss: 0.039007\n",
            "Train Epoch: 19 [44800/48000 (93%)]\tLoss: 0.082920\n",
            "\n",
            "Validation set: Average loss: 0.1982, Accuracy: 11301/12000 (94%)\n",
            "\n",
            "torch.Size([32]) torch.Size([32, 10])\n",
            "Train Epoch: 20 [0/48000 (0%)]\tLoss: 0.040846\n",
            "Train Epoch: 20 [6400/48000 (13%)]\tLoss: 0.173304\n",
            "Train Epoch: 20 [12800/48000 (27%)]\tLoss: 0.029403\n",
            "Train Epoch: 20 [19200/48000 (40%)]\tLoss: 0.110519\n",
            "Train Epoch: 20 [25600/48000 (53%)]\tLoss: 0.254314\n",
            "Train Epoch: 20 [32000/48000 (67%)]\tLoss: 0.106114\n",
            "Train Epoch: 20 [38400/48000 (80%)]\tLoss: 0.035041\n",
            "Train Epoch: 20 [44800/48000 (93%)]\tLoss: 0.093618\n",
            "\n",
            "Validation set: Average loss: 0.1975, Accuracy: 11306/12000 (94%)\n",
            "\n",
            "torch.Size([32]) torch.Size([32, 10])\n",
            "Train Epoch: 21 [0/48000 (0%)]\tLoss: 0.108856\n",
            "Train Epoch: 21 [6400/48000 (13%)]\tLoss: 0.061635\n",
            "Train Epoch: 21 [12800/48000 (27%)]\tLoss: 0.235661\n",
            "Train Epoch: 21 [19200/48000 (40%)]\tLoss: 0.197246\n",
            "Train Epoch: 21 [25600/48000 (53%)]\tLoss: 0.332718\n",
            "Train Epoch: 21 [32000/48000 (67%)]\tLoss: 0.292824\n",
            "Train Epoch: 21 [38400/48000 (80%)]\tLoss: 0.072618\n",
            "Train Epoch: 21 [44800/48000 (93%)]\tLoss: 0.058166\n",
            "\n",
            "Validation set: Average loss: 0.1937, Accuracy: 11302/12000 (94%)\n",
            "\n",
            "torch.Size([32]) torch.Size([32, 10])\n",
            "Train Epoch: 22 [0/48000 (0%)]\tLoss: 0.268044\n",
            "Train Epoch: 22 [6400/48000 (13%)]\tLoss: 0.149995\n",
            "Train Epoch: 22 [12800/48000 (27%)]\tLoss: 0.467542\n",
            "Train Epoch: 22 [19200/48000 (40%)]\tLoss: 0.045847\n",
            "Train Epoch: 22 [25600/48000 (53%)]\tLoss: 0.036417\n",
            "Train Epoch: 22 [32000/48000 (67%)]\tLoss: 0.024639\n",
            "Train Epoch: 22 [38400/48000 (80%)]\tLoss: 0.225389\n",
            "Train Epoch: 22 [44800/48000 (93%)]\tLoss: 0.337025\n",
            "\n",
            "Validation set: Average loss: 0.1909, Accuracy: 11323/12000 (94%)\n",
            "\n",
            "torch.Size([32]) torch.Size([32, 10])\n",
            "Train Epoch: 23 [0/48000 (0%)]\tLoss: 0.080114\n",
            "Train Epoch: 23 [6400/48000 (13%)]\tLoss: 0.084219\n",
            "Train Epoch: 23 [12800/48000 (27%)]\tLoss: 0.078452\n",
            "Train Epoch: 23 [19200/48000 (40%)]\tLoss: 0.070983\n",
            "Train Epoch: 23 [25600/48000 (53%)]\tLoss: 0.059509\n",
            "Train Epoch: 23 [32000/48000 (67%)]\tLoss: 0.124248\n",
            "Train Epoch: 23 [38400/48000 (80%)]\tLoss: 0.173276\n",
            "Train Epoch: 23 [44800/48000 (93%)]\tLoss: 0.465503\n",
            "\n",
            "Validation set: Average loss: 0.1903, Accuracy: 11337/12000 (94%)\n",
            "\n",
            "torch.Size([32]) torch.Size([32, 10])\n",
            "Train Epoch: 24 [0/48000 (0%)]\tLoss: 0.098929\n",
            "Train Epoch: 24 [6400/48000 (13%)]\tLoss: 0.158642\n",
            "Train Epoch: 24 [12800/48000 (27%)]\tLoss: 0.100256\n",
            "Train Epoch: 24 [19200/48000 (40%)]\tLoss: 0.220176\n",
            "Train Epoch: 24 [25600/48000 (53%)]\tLoss: 0.049823\n",
            "Train Epoch: 24 [32000/48000 (67%)]\tLoss: 0.169162\n",
            "Train Epoch: 24 [38400/48000 (80%)]\tLoss: 0.285179\n",
            "Train Epoch: 24 [44800/48000 (93%)]\tLoss: 0.041353\n",
            "\n",
            "Validation set: Average loss: 0.1893, Accuracy: 11351/12000 (95%)\n",
            "\n",
            "torch.Size([32]) torch.Size([32, 10])\n",
            "Train Epoch: 25 [0/48000 (0%)]\tLoss: 0.339605\n",
            "Train Epoch: 25 [6400/48000 (13%)]\tLoss: 0.129443\n",
            "Train Epoch: 25 [12800/48000 (27%)]\tLoss: 0.343644\n",
            "Train Epoch: 25 [19200/48000 (40%)]\tLoss: 0.090622\n",
            "Train Epoch: 25 [25600/48000 (53%)]\tLoss: 0.232191\n",
            "Train Epoch: 25 [32000/48000 (67%)]\tLoss: 0.108624\n",
            "Train Epoch: 25 [38400/48000 (80%)]\tLoss: 0.149153\n",
            "Train Epoch: 25 [44800/48000 (93%)]\tLoss: 0.262679\n",
            "\n",
            "Validation set: Average loss: 0.1851, Accuracy: 11356/12000 (95%)\n",
            "\n",
            "torch.Size([32]) torch.Size([32, 10])\n",
            "Train Epoch: 26 [0/48000 (0%)]\tLoss: 0.067205\n",
            "Train Epoch: 26 [6400/48000 (13%)]\tLoss: 0.295845\n",
            "Train Epoch: 26 [12800/48000 (27%)]\tLoss: 0.054124\n",
            "Train Epoch: 26 [19200/48000 (40%)]\tLoss: 0.105036\n",
            "Train Epoch: 26 [25600/48000 (53%)]\tLoss: 0.116307\n",
            "Train Epoch: 26 [32000/48000 (67%)]\tLoss: 0.037576\n",
            "Train Epoch: 26 [38400/48000 (80%)]\tLoss: 0.212936\n",
            "Train Epoch: 26 [44800/48000 (93%)]\tLoss: 0.233557\n",
            "\n",
            "Validation set: Average loss: 0.1833, Accuracy: 11353/12000 (95%)\n",
            "\n",
            "torch.Size([32]) torch.Size([32, 10])\n",
            "Train Epoch: 27 [0/48000 (0%)]\tLoss: 0.040285\n",
            "Train Epoch: 27 [6400/48000 (13%)]\tLoss: 0.057135\n",
            "Train Epoch: 27 [12800/48000 (27%)]\tLoss: 0.087604\n",
            "Train Epoch: 27 [19200/48000 (40%)]\tLoss: 0.034654\n",
            "Train Epoch: 27 [25600/48000 (53%)]\tLoss: 0.102137\n",
            "Train Epoch: 27 [32000/48000 (67%)]\tLoss: 0.201398\n",
            "Train Epoch: 27 [38400/48000 (80%)]\tLoss: 0.066818\n",
            "Train Epoch: 27 [44800/48000 (93%)]\tLoss: 0.058141\n",
            "\n",
            "Validation set: Average loss: 0.1821, Accuracy: 11354/12000 (95%)\n",
            "\n",
            "torch.Size([32]) torch.Size([32, 10])\n",
            "Train Epoch: 28 [0/48000 (0%)]\tLoss: 0.135025\n",
            "Train Epoch: 28 [6400/48000 (13%)]\tLoss: 0.304388\n",
            "Train Epoch: 28 [12800/48000 (27%)]\tLoss: 0.049744\n",
            "Train Epoch: 28 [19200/48000 (40%)]\tLoss: 0.071564\n",
            "Train Epoch: 28 [25600/48000 (53%)]\tLoss: 0.060068\n",
            "Train Epoch: 28 [32000/48000 (67%)]\tLoss: 0.121359\n",
            "Train Epoch: 28 [38400/48000 (80%)]\tLoss: 0.111376\n",
            "Train Epoch: 28 [44800/48000 (93%)]\tLoss: 0.123303\n",
            "\n",
            "Validation set: Average loss: 0.1827, Accuracy: 11356/12000 (95%)\n",
            "\n",
            "torch.Size([32]) torch.Size([32, 10])\n",
            "Train Epoch: 29 [0/48000 (0%)]\tLoss: 0.180635\n",
            "Train Epoch: 29 [6400/48000 (13%)]\tLoss: 0.098862\n",
            "Train Epoch: 29 [12800/48000 (27%)]\tLoss: 0.298953\n",
            "Train Epoch: 29 [19200/48000 (40%)]\tLoss: 0.172488\n",
            "Train Epoch: 29 [25600/48000 (53%)]\tLoss: 0.090343\n",
            "Train Epoch: 29 [32000/48000 (67%)]\tLoss: 0.096610\n",
            "Train Epoch: 29 [38400/48000 (80%)]\tLoss: 0.081848\n",
            "Train Epoch: 29 [44800/48000 (93%)]\tLoss: 0.349051\n",
            "\n",
            "Validation set: Average loss: 0.1806, Accuracy: 11373/12000 (95%)\n",
            "\n",
            "torch.Size([32]) torch.Size([32, 10])\n",
            "Train Epoch: 30 [0/48000 (0%)]\tLoss: 0.251708\n",
            "Train Epoch: 30 [6400/48000 (13%)]\tLoss: 0.068005\n",
            "Train Epoch: 30 [12800/48000 (27%)]\tLoss: 0.105985\n",
            "Train Epoch: 30 [19200/48000 (40%)]\tLoss: 0.128977\n",
            "Train Epoch: 30 [25600/48000 (53%)]\tLoss: 0.280428\n",
            "Train Epoch: 30 [32000/48000 (67%)]\tLoss: 0.172551\n",
            "Train Epoch: 30 [38400/48000 (80%)]\tLoss: 0.049371\n",
            "Train Epoch: 30 [44800/48000 (93%)]\tLoss: 0.077953\n",
            "\n",
            "Validation set: Average loss: 0.1813, Accuracy: 11369/12000 (95%)\n",
            "\n",
            "torch.Size([32]) torch.Size([32, 10])\n",
            "Train Epoch: 31 [0/48000 (0%)]\tLoss: 0.162695\n",
            "Train Epoch: 31 [6400/48000 (13%)]\tLoss: 0.064732\n",
            "Train Epoch: 31 [12800/48000 (27%)]\tLoss: 0.281634\n",
            "Train Epoch: 31 [19200/48000 (40%)]\tLoss: 0.026704\n",
            "Train Epoch: 31 [25600/48000 (53%)]\tLoss: 0.012734\n",
            "Train Epoch: 31 [32000/48000 (67%)]\tLoss: 0.225346\n",
            "Train Epoch: 31 [38400/48000 (80%)]\tLoss: 0.069339\n",
            "Train Epoch: 31 [44800/48000 (93%)]\tLoss: 0.081251\n",
            "\n",
            "Validation set: Average loss: 0.1781, Accuracy: 11377/12000 (95%)\n",
            "\n",
            "torch.Size([32]) torch.Size([32, 10])\n",
            "Train Epoch: 32 [0/48000 (0%)]\tLoss: 0.138709\n",
            "Train Epoch: 32 [6400/48000 (13%)]\tLoss: 0.274133\n",
            "Train Epoch: 32 [12800/48000 (27%)]\tLoss: 0.220046\n",
            "Train Epoch: 32 [19200/48000 (40%)]\tLoss: 0.136891\n",
            "Train Epoch: 32 [25600/48000 (53%)]\tLoss: 0.144826\n",
            "Train Epoch: 32 [32000/48000 (67%)]\tLoss: 0.144840\n",
            "Train Epoch: 32 [38400/48000 (80%)]\tLoss: 0.142360\n",
            "Train Epoch: 32 [44800/48000 (93%)]\tLoss: 0.036531\n",
            "\n",
            "Validation set: Average loss: 0.1823, Accuracy: 11358/12000 (95%)\n",
            "\n",
            "torch.Size([32]) torch.Size([32, 10])\n",
            "Train Epoch: 33 [0/48000 (0%)]\tLoss: 0.135959\n",
            "Train Epoch: 33 [6400/48000 (13%)]\tLoss: 0.109657\n",
            "Train Epoch: 33 [12800/48000 (27%)]\tLoss: 0.071271\n",
            "Train Epoch: 33 [19200/48000 (40%)]\tLoss: 0.239109\n",
            "Train Epoch: 33 [25600/48000 (53%)]\tLoss: 0.102903\n",
            "Train Epoch: 33 [32000/48000 (67%)]\tLoss: 0.062898\n",
            "Train Epoch: 33 [38400/48000 (80%)]\tLoss: 0.288236\n",
            "Train Epoch: 33 [44800/48000 (93%)]\tLoss: 0.051983\n",
            "\n",
            "Validation set: Average loss: 0.1776, Accuracy: 11360/12000 (95%)\n",
            "\n",
            "torch.Size([32]) torch.Size([32, 10])\n",
            "Train Epoch: 34 [0/48000 (0%)]\tLoss: 0.131618\n",
            "Train Epoch: 34 [6400/48000 (13%)]\tLoss: 0.097533\n",
            "Train Epoch: 34 [12800/48000 (27%)]\tLoss: 0.290388\n",
            "Train Epoch: 34 [19200/48000 (40%)]\tLoss: 0.083013\n",
            "Train Epoch: 34 [25600/48000 (53%)]\tLoss: 0.191348\n",
            "Train Epoch: 34 [32000/48000 (67%)]\tLoss: 0.167190\n",
            "Train Epoch: 34 [38400/48000 (80%)]\tLoss: 0.442479\n",
            "Train Epoch: 34 [44800/48000 (93%)]\tLoss: 0.040603\n",
            "\n",
            "Validation set: Average loss: 0.1778, Accuracy: 11364/12000 (95%)\n",
            "\n",
            "torch.Size([32]) torch.Size([32, 10])\n",
            "Train Epoch: 35 [0/48000 (0%)]\tLoss: 0.080813\n",
            "Train Epoch: 35 [6400/48000 (13%)]\tLoss: 0.018483\n",
            "Train Epoch: 35 [12800/48000 (27%)]\tLoss: 0.120417\n",
            "Train Epoch: 35 [19200/48000 (40%)]\tLoss: 0.098526\n",
            "Train Epoch: 35 [25600/48000 (53%)]\tLoss: 0.133078\n",
            "Train Epoch: 35 [32000/48000 (67%)]\tLoss: 0.024405\n",
            "Train Epoch: 35 [38400/48000 (80%)]\tLoss: 0.106441\n",
            "Train Epoch: 35 [44800/48000 (93%)]\tLoss: 0.056821\n",
            "\n",
            "Validation set: Average loss: 0.1772, Accuracy: 11372/12000 (95%)\n",
            "\n",
            "torch.Size([32]) torch.Size([32, 10])\n",
            "Train Epoch: 36 [0/48000 (0%)]\tLoss: 0.138651\n",
            "Train Epoch: 36 [6400/48000 (13%)]\tLoss: 0.182178\n",
            "Train Epoch: 36 [12800/48000 (27%)]\tLoss: 0.303252\n",
            "Train Epoch: 36 [19200/48000 (40%)]\tLoss: 0.052988\n",
            "Train Epoch: 36 [25600/48000 (53%)]\tLoss: 0.133366\n",
            "Train Epoch: 36 [32000/48000 (67%)]\tLoss: 0.191259\n",
            "Train Epoch: 36 [38400/48000 (80%)]\tLoss: 0.027470\n",
            "Train Epoch: 36 [44800/48000 (93%)]\tLoss: 0.124175\n",
            "\n",
            "Validation set: Average loss: 0.1747, Accuracy: 11375/12000 (95%)\n",
            "\n",
            "torch.Size([32]) torch.Size([32, 10])\n",
            "Train Epoch: 37 [0/48000 (0%)]\tLoss: 0.067290\n",
            "Train Epoch: 37 [6400/48000 (13%)]\tLoss: 0.030127\n",
            "Train Epoch: 37 [12800/48000 (27%)]\tLoss: 0.219798\n",
            "Train Epoch: 37 [19200/48000 (40%)]\tLoss: 0.023292\n",
            "Train Epoch: 37 [25600/48000 (53%)]\tLoss: 0.127519\n",
            "Train Epoch: 37 [32000/48000 (67%)]\tLoss: 0.097152\n",
            "Train Epoch: 37 [38400/48000 (80%)]\tLoss: 0.166053\n",
            "Train Epoch: 37 [44800/48000 (93%)]\tLoss: 0.102035\n",
            "\n",
            "Validation set: Average loss: 0.1778, Accuracy: 11383/12000 (95%)\n",
            "\n",
            "torch.Size([32]) torch.Size([32, 10])\n",
            "Train Epoch: 38 [0/48000 (0%)]\tLoss: 0.048692\n",
            "Train Epoch: 38 [6400/48000 (13%)]\tLoss: 0.019152\n",
            "Train Epoch: 38 [12800/48000 (27%)]\tLoss: 0.290737\n",
            "Train Epoch: 38 [19200/48000 (40%)]\tLoss: 0.137402\n",
            "Train Epoch: 38 [25600/48000 (53%)]\tLoss: 0.036397\n",
            "Train Epoch: 38 [32000/48000 (67%)]\tLoss: 0.112537\n",
            "Train Epoch: 38 [38400/48000 (80%)]\tLoss: 0.044764\n",
            "Train Epoch: 38 [44800/48000 (93%)]\tLoss: 0.094095\n",
            "\n",
            "Validation set: Average loss: 0.1760, Accuracy: 11391/12000 (95%)\n",
            "\n",
            "torch.Size([32]) torch.Size([32, 10])\n",
            "Train Epoch: 39 [0/48000 (0%)]\tLoss: 0.637308\n",
            "Train Epoch: 39 [6400/48000 (13%)]\tLoss: 0.207606\n",
            "Train Epoch: 39 [12800/48000 (27%)]\tLoss: 0.194922\n",
            "Train Epoch: 39 [19200/48000 (40%)]\tLoss: 0.028017\n",
            "Train Epoch: 39 [25600/48000 (53%)]\tLoss: 0.166848\n",
            "Train Epoch: 39 [32000/48000 (67%)]\tLoss: 0.159348\n",
            "Train Epoch: 39 [38400/48000 (80%)]\tLoss: 0.020345\n",
            "Train Epoch: 39 [44800/48000 (93%)]\tLoss: 0.082740\n",
            "\n",
            "Validation set: Average loss: 0.1751, Accuracy: 11374/12000 (95%)\n",
            "\n",
            "torch.Size([32]) torch.Size([32, 10])\n",
            "Train Epoch: 40 [0/48000 (0%)]\tLoss: 0.156084\n",
            "Train Epoch: 40 [6400/48000 (13%)]\tLoss: 0.044395\n",
            "Train Epoch: 40 [12800/48000 (27%)]\tLoss: 0.185661\n",
            "Train Epoch: 40 [19200/48000 (40%)]\tLoss: 0.031286\n",
            "Train Epoch: 40 [25600/48000 (53%)]\tLoss: 0.054321\n",
            "Train Epoch: 40 [32000/48000 (67%)]\tLoss: 0.016531\n",
            "Train Epoch: 40 [38400/48000 (80%)]\tLoss: 0.021756\n",
            "Train Epoch: 40 [44800/48000 (93%)]\tLoss: 0.178794\n",
            "\n",
            "Validation set: Average loss: 0.1748, Accuracy: 11395/12000 (95%)\n",
            "\n",
            "torch.Size([32]) torch.Size([32, 10])\n",
            "Train Epoch: 41 [0/48000 (0%)]\tLoss: 0.373021\n",
            "Train Epoch: 41 [6400/48000 (13%)]\tLoss: 0.068502\n",
            "Train Epoch: 41 [12800/48000 (27%)]\tLoss: 0.079424\n",
            "Train Epoch: 41 [19200/48000 (40%)]\tLoss: 0.056162\n",
            "Train Epoch: 41 [25600/48000 (53%)]\tLoss: 0.161510\n",
            "Train Epoch: 41 [32000/48000 (67%)]\tLoss: 0.290974\n",
            "Train Epoch: 41 [38400/48000 (80%)]\tLoss: 0.151250\n",
            "Train Epoch: 41 [44800/48000 (93%)]\tLoss: 0.054048\n",
            "\n",
            "Validation set: Average loss: 0.1757, Accuracy: 11368/12000 (95%)\n",
            "\n",
            "torch.Size([32]) torch.Size([32, 10])\n",
            "Train Epoch: 42 [0/48000 (0%)]\tLoss: 0.032020\n",
            "Train Epoch: 42 [6400/48000 (13%)]\tLoss: 0.143841\n",
            "Train Epoch: 42 [12800/48000 (27%)]\tLoss: 0.110194\n",
            "Train Epoch: 42 [19200/48000 (40%)]\tLoss: 0.033837\n",
            "Train Epoch: 42 [25600/48000 (53%)]\tLoss: 0.082824\n",
            "Train Epoch: 42 [32000/48000 (67%)]\tLoss: 0.064018\n",
            "Train Epoch: 42 [38400/48000 (80%)]\tLoss: 0.054422\n",
            "Train Epoch: 42 [44800/48000 (93%)]\tLoss: 0.196336\n",
            "\n",
            "Validation set: Average loss: 0.1761, Accuracy: 11384/12000 (95%)\n",
            "\n",
            "torch.Size([32]) torch.Size([32, 10])\n",
            "Train Epoch: 43 [0/48000 (0%)]\tLoss: 0.100573\n",
            "Train Epoch: 43 [6400/48000 (13%)]\tLoss: 0.037885\n",
            "Train Epoch: 43 [12800/48000 (27%)]\tLoss: 0.024774\n",
            "Train Epoch: 43 [19200/48000 (40%)]\tLoss: 0.113259\n",
            "Train Epoch: 43 [25600/48000 (53%)]\tLoss: 0.331571\n",
            "Train Epoch: 43 [32000/48000 (67%)]\tLoss: 0.156241\n",
            "Train Epoch: 43 [38400/48000 (80%)]\tLoss: 0.119673\n",
            "Train Epoch: 43 [44800/48000 (93%)]\tLoss: 0.133812\n",
            "\n",
            "Validation set: Average loss: 0.1730, Accuracy: 11384/12000 (95%)\n",
            "\n",
            "torch.Size([32]) torch.Size([32, 10])\n",
            "Train Epoch: 44 [0/48000 (0%)]\tLoss: 0.182920\n",
            "Train Epoch: 44 [6400/48000 (13%)]\tLoss: 0.034681\n",
            "Train Epoch: 44 [12800/48000 (27%)]\tLoss: 0.077938\n",
            "Train Epoch: 44 [19200/48000 (40%)]\tLoss: 0.210680\n",
            "Train Epoch: 44 [25600/48000 (53%)]\tLoss: 0.058884\n",
            "Train Epoch: 44 [32000/48000 (67%)]\tLoss: 0.166620\n",
            "Train Epoch: 44 [38400/48000 (80%)]\tLoss: 0.167258\n",
            "Train Epoch: 44 [44800/48000 (93%)]\tLoss: 0.372893\n",
            "\n",
            "Validation set: Average loss: 0.1759, Accuracy: 11367/12000 (95%)\n",
            "\n",
            "torch.Size([32]) torch.Size([32, 10])\n",
            "Train Epoch: 45 [0/48000 (0%)]\tLoss: 0.158374\n",
            "Train Epoch: 45 [6400/48000 (13%)]\tLoss: 0.418108\n",
            "Train Epoch: 45 [12800/48000 (27%)]\tLoss: 0.200538\n",
            "Train Epoch: 45 [19200/48000 (40%)]\tLoss: 0.045431\n",
            "Train Epoch: 45 [25600/48000 (53%)]\tLoss: 0.061246\n",
            "Train Epoch: 45 [32000/48000 (67%)]\tLoss: 0.270195\n",
            "Train Epoch: 45 [38400/48000 (80%)]\tLoss: 0.198289\n",
            "Train Epoch: 45 [44800/48000 (93%)]\tLoss: 0.138953\n",
            "\n",
            "Validation set: Average loss: 0.1783, Accuracy: 11355/12000 (95%)\n",
            "\n",
            "torch.Size([32]) torch.Size([32, 10])\n",
            "Train Epoch: 46 [0/48000 (0%)]\tLoss: 0.034017\n",
            "Train Epoch: 46 [6400/48000 (13%)]\tLoss: 0.073842\n",
            "Train Epoch: 46 [12800/48000 (27%)]\tLoss: 0.029260\n",
            "Train Epoch: 46 [19200/48000 (40%)]\tLoss: 0.155346\n",
            "Train Epoch: 46 [25600/48000 (53%)]\tLoss: 0.062112\n",
            "Train Epoch: 46 [32000/48000 (67%)]\tLoss: 0.025374\n",
            "Train Epoch: 46 [38400/48000 (80%)]\tLoss: 0.050692\n",
            "Train Epoch: 46 [44800/48000 (93%)]\tLoss: 0.091276\n",
            "\n",
            "Validation set: Average loss: 0.1718, Accuracy: 11392/12000 (95%)\n",
            "\n",
            "torch.Size([32]) torch.Size([32, 10])\n",
            "Train Epoch: 47 [0/48000 (0%)]\tLoss: 0.090577\n",
            "Train Epoch: 47 [6400/48000 (13%)]\tLoss: 0.021024\n",
            "Train Epoch: 47 [12800/48000 (27%)]\tLoss: 0.121984\n",
            "Train Epoch: 47 [19200/48000 (40%)]\tLoss: 0.035655\n",
            "Train Epoch: 47 [25600/48000 (53%)]\tLoss: 0.162632\n",
            "Train Epoch: 47 [32000/48000 (67%)]\tLoss: 0.079732\n",
            "Train Epoch: 47 [38400/48000 (80%)]\tLoss: 0.063734\n",
            "Train Epoch: 47 [44800/48000 (93%)]\tLoss: 0.078254\n",
            "\n",
            "Validation set: Average loss: 0.1727, Accuracy: 11376/12000 (95%)\n",
            "\n",
            "torch.Size([32]) torch.Size([32, 10])\n",
            "Train Epoch: 48 [0/48000 (0%)]\tLoss: 0.010317\n",
            "Train Epoch: 48 [6400/48000 (13%)]\tLoss: 0.090597\n",
            "Train Epoch: 48 [12800/48000 (27%)]\tLoss: 0.013228\n",
            "Train Epoch: 48 [19200/48000 (40%)]\tLoss: 0.012984\n",
            "Train Epoch: 48 [25600/48000 (53%)]\tLoss: 0.043006\n",
            "Train Epoch: 48 [32000/48000 (67%)]\tLoss: 0.047336\n",
            "Train Epoch: 48 [38400/48000 (80%)]\tLoss: 0.321248\n",
            "Train Epoch: 48 [44800/48000 (93%)]\tLoss: 0.056046\n",
            "\n",
            "Validation set: Average loss: 0.1693, Accuracy: 11401/12000 (95%)\n",
            "\n",
            "torch.Size([32]) torch.Size([32, 10])\n",
            "Train Epoch: 49 [0/48000 (0%)]\tLoss: 0.137609\n",
            "Train Epoch: 49 [6400/48000 (13%)]\tLoss: 0.019088\n",
            "Train Epoch: 49 [12800/48000 (27%)]\tLoss: 0.029495\n",
            "Train Epoch: 49 [19200/48000 (40%)]\tLoss: 0.135918\n",
            "Train Epoch: 49 [25600/48000 (53%)]\tLoss: 0.077214\n",
            "Train Epoch: 49 [32000/48000 (67%)]\tLoss: 0.038420\n",
            "Train Epoch: 49 [38400/48000 (80%)]\tLoss: 0.067517\n",
            "Train Epoch: 49 [44800/48000 (93%)]\tLoss: 0.455494\n",
            "\n",
            "Validation set: Average loss: 0.1715, Accuracy: 11399/12000 (95%)\n",
            "\n",
            "torch.Size([32]) torch.Size([32, 10])\n",
            "Train Epoch: 50 [0/48000 (0%)]\tLoss: 0.429282\n",
            "Train Epoch: 50 [6400/48000 (13%)]\tLoss: 0.165586\n",
            "Train Epoch: 50 [12800/48000 (27%)]\tLoss: 0.030603\n",
            "Train Epoch: 50 [19200/48000 (40%)]\tLoss: 0.081664\n",
            "Train Epoch: 50 [25600/48000 (53%)]\tLoss: 0.085115\n",
            "Train Epoch: 50 [32000/48000 (67%)]\tLoss: 0.177931\n",
            "Train Epoch: 50 [38400/48000 (80%)]\tLoss: 0.026402\n",
            "Train Epoch: 50 [44800/48000 (93%)]\tLoss: 0.170006\n",
            "\n",
            "Validation set: Average loss: 0.1720, Accuracy: 11389/12000 (95%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.1520, Accuracy: 9569/10000 (96%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(epochs):\n",
        "    train(log_interval, model, device, train_loader, optimizer, epoch)\n",
        "    validation(model, device, validation_loader)\n",
        "test(model, device, test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kS-ouOru6ha_"
      },
      "source": [
        "*학습된 모델을 바탕으로 각 사진 별 예측을 진행 해봅시다.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "Z4Rl-zJ-6ha_",
        "outputId": "9735dd96-da80-4235-d616-d11188694d6b"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predict:  tensor(3, device='cuda:0')\n",
            "Correct:  tensor(3)\n"
          ]
        }
      ],
      "source": [
        "image_batch, label = next(iter(train_loader))\n",
        "\n",
        "image_idx = 5\n",
        "\n",
        "img = image_batch[image_idx, 0, :, :]\n",
        "plt.imshow(img, 'gray')\n",
        "plt.show()\n",
        "img = img.to(device)\n",
        "output = model(img)\n",
        "pred = output.argmax(dim=1, keepdim=True)\n",
        "\n",
        "print(\"Predict: \", pred[0, 0])\n",
        "print(\"Correct: \", label[image_idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jbpIkxSL_WCd"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
